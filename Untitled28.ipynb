{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "siyEMaUw2_Zq",
        "outputId": "e6efb3a8-2754-471c-cb66-4ef329f81544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
                   },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LSTM model...\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 75ms/step - accuracy: 0.7779 - loss: 0.5039 - val_accuracy: 0.8374 - val_loss: 0.3843\n",
            "Epoch 2/3\n",
            "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 75ms/step - accuracy: 0.8721 - loss: 0.3064 - val_accuracy: 0.8362 - val_loss: 0.3854\n",
            "Epoch 3/3\n",
            "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 80ms/step - accuracy: 0.9023 - loss: 0.2417 - val_accuracy: 0.8368 - val_loss: 0.4348\n",
            "LSTM Training Time: 106.85 seconds (~1.78 minutes)\n",
            "\n",
            "Evaluating LSTM model...\n",
            "LSTM Test Accuracy: 0.8339\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png":           },
          "metadata": {}
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install tensorflow pandas numpy scikit-learn nltk matplotlib\n",
        "\n",
        "# Clone the FakeNewsNet repository\n",
        "!git clone https://github.com/KaiDMML/FakeNewsNet.git\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define paths to the dataset files\n",
        "dataset_path = '/content/FakeNewsNet/dataset/'\n",
        "\n",
        "# Load the datasets\n",
        "politifact_fake = pd.read_csv(os.path.join(dataset_path, 'politifact_fake.csv'))\n",
        "politifact_real = pd.read_csv(os.path.join(dataset_path, 'politifact_real.csv'))\n",
        "gossipcop_fake = pd.read_csv(os.path.join(dataset_path, 'gossipcop_fake.csv'))\n",
        "gossipcop_real = pd.read_csv(os.path.join(dataset_path, 'gossipcop_real.csv'))\n",
        "\n",
        "# Add labels: 1 for fake, 0 for real\n",
        "politifact_fake['label'] = 1\n",
        "politifact_real['label'] = 0\n",
        "gossipcop_fake['label'] = 1\n",
        "gossipcop_real['label'] = 0\n",
        "\n",
        "# Combine the datasets\n",
        "data = pd.concat([politifact_fake, politifact_real, gossipcop_fake, gossipcop_real], ignore_index=True)\n",
        "\n",
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    if pd.isna(text):  # Handle missing values\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = ' '.join(word for word in text.split() if word not in stopwords.words('english'))\n",
        "    return text.strip()\n",
        "\n",
        "# Apply preprocessing to the 'title' column\n",
        "data['cleaned_text'] = data['title'].apply(preprocess_text)\n",
        "\n",
        "# Remove empty or invalid entries\n",
        "data = data[data['cleaned_text'] != '']\n",
        "\n",
        "# Prepare data\n",
        "texts = data['cleaned_text'].values\n",
        "labels = data['label'].values\n",
        "\n",
        "# Tokenization and padding\n",
        "max_words = 5000  # Maximum number of words to keep\n",
        "max_len = 100     # Maximum length of each sequence\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "X = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Convert labels to categorical\n",
        "y = to_categorical(labels)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 100, input_length=max_len))\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with time measurement\n",
        "print(\"Training LSTM model...\")\n",
        "start_time = time.time()\n",
        "history = model.fit(X_train, y_train, epochs=3, batch_size=32, validation_split=0.2, verbose=1)\n",
        "lstm_train_time = time.time() - start_time\n",
        "print(f\"LSTM Training Time: {lstm_train_time:.2f} seconds (~{lstm_train_time/60:.2f} minutes)\")\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\nEvaluating LSTM model...\")\n",
        "loss, lstm_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"LSTM Test Accuracy: {lstm_accuracy:.4f}\")\n",
        "\n",
        "# Comparison data (BERT from previous discussions)\n",
        "bert_accuracy = 0.85  # Estimated average accuracy from earlier (~85-90%)\n",
        "bert_train_time = 25  # Estimated average time in minutes (~25-30 minutes)\n",
        "\n",
        "# Plotting accuracy and time comparison\n",
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Accuracy plot (primary y-axis)\n",
        "ax1.set_xlabel('Model')\n",
        "ax1.set_ylabel('Accuracy', color='tab:blue')\n",
        "models = ['LSTM', 'BERT']\n",
        "accuracies = [lstm_accuracy * 100, bert_accuracy * 100]\n",
        "ax1.bar(models, accuracies, color=['tab:blue', 'tab:orange'], alpha=0.7)\n",
        "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
        "ax1.set_ylim(0, 100)\n",
        "\n",
        "# Time plot (secondary y-axis)\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel('Training Time (minutes)', color='tab:red')\n",
        "times = [lstm_train_time/60, bert_train_time]\n",
        "ax2.plot(models, times, color='tab:red', marker='o', label='Time')\n",
        "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
        "ax2.set_ylim(0, 40)\n",
        "\n",
        "# Title and legend\n",
        "plt.title('LSTM vs BERT: Accuracy and Training Time Comparison')\n",
        "fig.legend(loc='upper left', bbox_to_anchor=(0.1,0.9))\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ]
    }
  ]
}
